{
  "purpose": "Accurate answers for the new agent about areas that were previously 'less deep'. No guesswork, no inflation. Traced from the actual codebase.",
  "source_project_root": "c:\\CURSOR\\lm-studio-ui",
  "DashboardArena": {
    "summary": "Arena layout: one shared prompt sent to 1–4 model slots (A/B/C/D). Each slot has its own message list and stream; parallel or sequential; single ChatInput at bottom (must be replaced by new agent's input).",
    "how_A_B_C_D_run": "sendUserMessage(text, imageDataUrls) is the entry (called by ChatInput's onSend). It reads arenaPanelCount and dashboardModelA/B/C/D; builds slotsActive = ['A'] plus B/C/D if panelCount >= 2/3/4; filters to selected = slots that have a modelId. If sequential (localStorage arenaSequential): for (s of selected) await sendToSlot(s.slot, s.modelId, content, onStreamDone). If parallel: Promise.allSettled(selected.map(s => sendToSlot(...))). So parallel = all slots stream at once; sequential = A then B then C then D.",
    "sendToSlot": "For one slot: push user message and assistant placeholder to that slot's message array; buildApiMessages from that slot's messages (plus system prompt); create AbortController stored in aborters[slot]; call streamChatCompletion with onChunk (append to fullContent, detectLoop→abort, liveTokens.set, pushTokSample, updateMessage for that assistant), onDone (setRunning(slot, false), onStreamDone callback), onUsage; on completion update message with stats. Each slot has its own messagesA/B/C/D, running.A/B/C/D, slotErrors.A/B/C/D.",
    "column_rendering": "One grid (grid-template-columns from responsiveGridCols). effectiveCols: mobile=1, tablet=min(panelCount,2), desktop=panelCount. responsiveGridCols: mobile/tablet use repeat(effectiveCols, minmax(0,1fr)); desktop use gridCols which is percentages from panelWidths (resizable; localStorage arenaPanelWidths). Four blocks: {#if arenaPanelCount >= 1} column A (header: Model A, running/tps, clear; body: MessageBubble each messagesA); same for 2/3/4 with B/C/D. Resize handles between columns (startResize, onResizeMove, endResize) update panelWidths and save. ModelSelectorSlot is used in App.svelte header for Arena (one slot per column); DashboardArena does not use ModelSelectorSlot—it only uses dashboardModelA/B/C/D from stores.",
    "ChatInput_usage": "At bottom: ChatInput onSend={sendUserMessage} onStop={stopAll}. One shared input; same prompt goes to all selected slots. New agent must replace this with their own input component that calls the same sendUserMessage(text, imageDataUrls) and stopAll().",
    "not_traced": "I did not trace where floatingMetricsOpen is toggled (e.g. from CommandPalette or a menu). Arena-specific keyboard shortcuts if any."
  },
  "IntelPanel": {
    "summary": "Cockpit right sidebar panel. Shows context usage, current model, params (temperature/top-p/top-k), and response log.",
    "data_shown": "1) Context: progress bar contextPercent = estimatedContextUsed/contextLength; estimatedContextUsed = sum over activeMessages of ceil(text.length/4); contextLength from settings (default 4096). Button 'Reset context' calls createConversation, listConversations, set activeConversationId. 2) Current model: selectedModelId; getModelIcon(currentModelId), getQuantization(currentModelId); Settings button opens settingsOpen. 3) Parameters: temperature, topP, topK from settings; three range inputs that call updateSettings({ temperature }, { top_p }, { top_k }). 4) Response log: responseHistory = last MAX_HISTORY (5) completions; each row has tokens, tps, elapsedMs. Pushed when lastResponseTokPerSec and lastResponseTokens update (from ChatView stream completion).",
    "stores_used": "settings, selectedModelId, lastResponseTokPerSec, lastResponseTokens, activeMessages, updateSettings, settingsOpen, activeConversationId, conversations. Plus createConversation, listConversations, getMessageCount from db; getModelIcon, getQuantization, modelIconOverrides from modelIcons.",
    "not_traced": "Whether IntelPanel is used anywhere other than App.svelte cockpit branch. Exact timing of when responseHistory is pushed (effect dependency on tpsVal/tokensVal)."
  },
  "FloatingMetricsDashboard_and_PerfStats": {
    "FloatingMetricsDashboard": "Floating draggable panel. Reads: floatingMetricsOpen, floatingMetricsMinimized, floatingMetricsPosition, tokSeries, liveTokPerSec, lastResponseTokPerSec. Renders: when open, a header (Metrics, minimize, close) and if not minimized: current tok/s (liveTokPerSec ?? lastResponseTokPerSec ?? '—') and an SVG sparkline from tokSeries (array of up to 60 samples). pathPoints = tokSeries mapped to x,y; polyline + hover to show value at index. Position is draggable (startDrag, onMove, endDrag; floatingMetricsPosition.set). Persistence: stores.js subscribes floatingMetricsOpen/minimized/position and writes to localStorage 'floatingMetrics'.",
    "where_tok_data_comes_from": "pushTokSample(rate) in stores.js: sets liveTokPerSec.set(r) and tokSeries.update(arr => [...arr.slice(-59), r]). pushTokSample is called from: (1) ChatView onChunk when streaming—every 1s it computes rate from fullContent length delta and calls pushTokSample(rate); (2) DashboardArena sendToSlot onChunk—same pattern, every 1s pushTokSample(rate). So both cockpit stream and arena slot streams feed the same tokSeries/liveTokPerSec. When stream ends, ChatView/DashboardArena set liveTokens.set(null), liveTokPerSec.set(null); lastResponseTokPerSec is set from final stats (completion_tokens / (elapsed_ms/1000)).",
    "PerfStats": "Presentational only. Props: stats (optional { completion_tokens, elapsed_ms, prompt_tokens, estimated }), contentLength, elapsedMs. Derives: completion tokens (from stats or ceil(contentLength/4)), elapsedSec, tokensPerSec, promptTokens, isEstimated. Renders: tok/s, completion tokens, prompt tokens, elapsed ms, (est.) label. Used by MessageBubble to show per-message stats below a bubble. No store dependency; parent passes stats.",
    "not_traced": "Where floatingMetricsOpen is set to true initially or by user action (likely CommandPalette or a header button). resetTokSeries call sites."
  },
  "file_handling_and_web_search": {
    "file_handler": "fileHandler.js: routeFile(file, { modelId }) and routeFiles(files, { modelId }). routeFile: images → { imageFile }; PDF → pdfToImages (pdfjs-dist render each page to PNG), return { imageFiles, prepend }; .txt/.py → readTextFile, return { prepend }. routeFiles: loops files, calls routeFile each, merges prepends, collects imageFiles. Used only from ChatInput: handleFiles (file picker) and handlePaste (image paste) call routeFiles/routeFile; prepend goes to text state, imageFiles become data URLs in images array then sent as image_url in message content. PDF uses pdfjs-dist (worker from pdfjs-dist/build/pdf.worker.mjs).",
    "web_search_flow": "Store webSearchForNextMessage: when true, next send is a web search. ChatInput: if onSearchWeb && webSearchForNextMessage in handleSubmit, calls onSearchWeb(t) and returns (no normal send). ChatView passes onSearchWeb={runWebSearch}. runWebSearch(query): sets webSearchInProgress.set(true), searchDuckDuckGo(q), formatSearchResultForChat(q, result), sendUserMessage(formatted), finally webSearchInProgress.set(false). So the user message is the formatted search result block; then the model streams a reply to that.",
    "duckduckgo": "searchDuckDuckGo(query) in duckduckgo.js. Uses searchDuckDuckGoLite: fetches DuckDuckGo Lite HTML via CORS proxy (corsproxy.io or allorigins.win), parses with DOMParser, queries a[href*='uddg='], extracts title/snippet/url, up to 8 results. formatSearchResultForChat(query, results) returns a string (or structured block) for the chat. No API key.",
    "not_traced": "Full formatSearchResultForChat output shape. Whether web search path supports images. Exact error handling in routeFiles when one file fails."
  },
  "gaps_that_do_not_block": "The above is enough to copy or rewire Arena, Intel, metrics, and file/search. If the new agent needs one place deeper (e.g. exact formatSearchResultForChat string, or where floatingMetricsOpen is opened), they can grep for that symbol in the repo."
}
